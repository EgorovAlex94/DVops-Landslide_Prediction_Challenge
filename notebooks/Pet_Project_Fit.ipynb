{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc43cee9",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22d8af",
   "metadata": {},
   "source": [
    "## 1. Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ea8fec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1672/1086136549.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import statistics\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error,  accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
    "    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n",
    "    precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression, load_boston, load_iris\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, \\\n",
    "StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet,\\\n",
    "RidgeClassifier, LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, accuracy_score, \\\n",
    "roc_auc_score, classification_report, r2_score, precision_score, recall_score, \\\n",
    "log_loss, mean_squared_log_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
    "    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n",
    "    precision_recall_curve, roc_curve\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, precision_score, recall_score, \\\n",
    "    f1_score, log_loss, classification_report, roc_curve, auc, roc_auc_score, r2_score, \\\n",
    "    mean_squared_log_error\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "RAND = 10\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746f123",
   "metadata": {},
   "source": [
    "## 2. Загрузка подготовленного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea32434",
   "metadata": {},
   "source": [
    "## 3. Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769f146",
   "metadata": {},
   "source": [
    "### 3.1. Catboost baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Sample_ID', \"Label\"], axis=1)\n",
    "y = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6842eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=RAND)\n",
    "\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train,\n",
    "                                                    y_train,\n",
    "                                                    test_size=0.16,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=RAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f24bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X_val.select_dtypes('category').columns.tolist()\n",
    "\n",
    "clfcat = CatBoostClassifier(scale_pos_weight=y.agg(lambda x: x.eq(0).sum()) /\n",
    "                            y.agg(lambda x: x.eq(1).sum()),\n",
    "                            random_state=RAND,\n",
    "                            eval_metric=\"F1\",\n",
    "                            cat_features=cat_features)\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clfcat.fit(X_train_,\n",
    "           y_train_,\n",
    "           eval_set=eval_set,\n",
    "           early_stopping_rounds=100,\n",
    "           verbose=False)\n",
    "\n",
    "y_pred_cat = clfcat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f12a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_score, name):\n",
    "    df_metrics = pd.DataFrame()\n",
    "    \n",
    "    df_metrics['model'] = [name]\n",
    "    \n",
    "    # Основные метрики для задачи классификации\n",
    "    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n",
    "    \n",
    "    # В ROC-AUC подаем фактические значения y и вероятности!!!!\n",
    "    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score[:,1])]\n",
    "    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n",
    "    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n",
    "    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n",
    "    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de22659",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clfcat.predict_proba(X_test)\n",
    "\n",
    "metrics = get_metrics(y_test,\n",
    "                      y_pred_cat,\n",
    "                      y_score,\n",
    "                      name='Catboost_baseline_test')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6202c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = clfcat.predict_proba(X_train)\n",
    "y_pred_cat_train = clfcat.predict(X_train)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='Catboost_baseline_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Underfitting, берем f1 за eval_metric и loss function! =)\n",
    "\n",
    "и далее так везде\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80936897",
   "metadata": {},
   "source": [
    "### 3.2. Catboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "\n",
    "cat_feat = X_train.select_dtypes('category').columns.tolist()\n",
    "\n",
    "\n",
    "def objective_cat_first(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\",\n",
    "                                             0.001,\n",
    "                                             0.5,\n",
    "                                             log=True),\n",
    "        \"random_state\": RAND\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=eval_data,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = f1_score(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1cfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"Cat_02\")\n",
    "func = lambda trial: objective_cat_first(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND, cat_feat=cat_feat)\n",
    "# n_trials - кол-во итераций\n",
    "study_cat.optimize(func, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ba207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat_second(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\",\n",
    "                                  [0.09121441559229158]),  # 0.07\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"l2_leaf_reg\":\n",
    "        trial.suggest_uniform(\"l2_leaf_reg\", 1e-5, 1e2),\n",
    "        \"random_strength\":\n",
    "        trial.suggest_uniform(\"random_strength\", 10, 50),\n",
    "        \"border_count\":\n",
    "        trial.suggest_categorical(\"border_count\", [128, 254]),\n",
    "        # \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\", \"No\"]),\n",
    "        # \"grow_policy\":\n",
    "        # trial.suggest_categorical(\"grow_policy\",\n",
    "        #                        [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]),\n",
    "        # \"od_wait\":\n",
    "        # trial.suggest_int(\"od_wait\", 500, 2000),\n",
    "        # \"leaf_estimation_iterations\":\n",
    "        #trial.suggest_int('leaf_estimation_iterations', 1, 15),\n",
    "        # \"cat_features\": trial.suggest_categorical(\"cat_features\", [\"cat_features\"]),\n",
    "        \"use_best_model\":\n",
    "        trial.suggest_categorical(\"use_best_model\", [True]),\n",
    "         \"eval_metric\":\n",
    "         trial.suggest_categorical(\"eval_metric\", [\"F1\"]),\n",
    "        \"loss_function\":\n",
    "        trial.suggest_categorical(\"loss_function\", [\"Logloss\"]),\n",
    "        # \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        # \"class_weights\": trial.suggest_categorical(\"class_weights\", [1]),\n",
    "        \"scale_pos_weight\":\n",
    "        trial.suggest_categorical(\n",
    "            \"scale_pos_weight\",\n",
    "            [y.agg(lambda x: x.eq(0).sum()) / y.agg(lambda x: x.eq(1).sum())]),\n",
    "        \"random_state\":\n",
    "        RAND\n",
    "    }\n",
    "\n",
    "    # if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "    #  params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    # elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "    #  params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n",
    "\n",
    "    # if params[\"grow_policy\"] == \"Lossguide\":\n",
    "    # params[\"num_leaves\"] = trial.suggest_int(\"num_leaves\", 20, 1000)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=eval_data,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = f1_score(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4bdc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"Cat_02\")\n",
    "func = lambda trial: objective_cat_second(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND, cat_feat=cat_feat)\n",
    "# n_trials - кол-во итераций\n",
    "study_cat.optimize(func, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5318f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cat.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_optuna = CatBoostClassifier(**study_cat.best_params)\n",
    "cat_optuna.fit(X_train_,\n",
    "               y_train_,\n",
    "               cat_features=cat_features,\n",
    "               eval_set=eval_set,\n",
    "               verbose=False,\n",
    "               early_stopping_rounds=100)\n",
    "\n",
    "y_pred = cat_optuna.predict(X_test)\n",
    "y_score = cat_optuna.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test=y_test,\n",
    "                y_pred=y_pred,\n",
    "                y_score=y_score,\n",
    "                name='CatBoost_Optuna_test'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f185836",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = cat_optuna.predict_proba(X_train)\n",
    "y_pred_cat_train = cat_optuna.predict(X_train)\n",
    "\n",
    "metrics =metrics.append(get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='CatBoost_Optuna_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb24d6a",
   "metadata": {},
   "source": [
    "### 3.3. Catboost holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "это уже фунциями для стекинга =)\n",
    "это не holdout\n",
    "\n",
    "Я забрал его прям с лекции по бустингам, там не было стекинга...\n",
    "Просто добавил вконце 5 строк, чтобы параллельно с обычными моделями, строилась таблица для стекинга.\n",
    "Поправьте, пожалуйста, если ошибаюсь)\n",
    "\n",
    "\n",
    "в этой функции тут смысла нет, если просто holdout, лучше без неее\n",
    "но вы же помои хотите в стегинге применять, лучше написать это словами\n",
    "\n",
    "НО, я увидела ниже, что далее функцию не применяете у другим алгоритмам, убираем ее и делаем как ниже у вас\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81239537",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X = pd.DataFrame()\n",
    "meta_X_test = pd.DataFrame()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS)\n",
    "\n",
    "score_oof = []\n",
    "predictions_test = []\n",
    "finish_test_preds_proba = []\n",
    "pred_val = []\n",
    "pred_score_val = []\n",
    "early_stop=True\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_val = X_train.iloc[train_idx], X_train.iloc[train_idx]\n",
    "    y_train_, y_val = y_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    \n",
    "    model = CatBoostClassifier(**study_cat.best_params)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "                y_train_,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                silent=True,\n",
    "                cat_features=cat_features,\n",
    "                early_stopping_rounds=100)\n",
    "\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds_test_proba = model.predict_proba(X_test)\n",
    "    finish_test_preds_proba.append(preds_test_proba)\n",
    "\n",
    "    print(\n",
    "        \"Fold:\", fold + 1,\n",
    "        \"f1_score %.3f\" % f1_score(y_val, y_pred_val))\n",
    "    print(\"---\")\n",
    "\n",
    "    # oof list\n",
    "    score_oof.append(f1_score(y_val, y_pred_val))\n",
    "    # holdout list\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "    predictions_test.append(y_pred)\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)\n",
    "meta_X['cat_hold'] = model.predict_proba(X_train)[:,1]\n",
    "meta_X_test['cat_hold'] = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ab68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = np.mean(finish_test_preds_proba, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "test_pred = stats.mode(np.column_stack(predictions_test), axis=1)[0]\n",
    "\n",
    "# oof - out-of-fold  - предсказания/значение метрики при обучении модели\n",
    "# в ходе перекрестной проверки на validation data\n",
    "print('F1 mean OOF: %.3f, std: %.3f' %\n",
    "      (np.mean(score_oof), np.std(score_oof)))\n",
    "\n",
    "# holdout  - предсказания/значение метрики при обучении модели\n",
    "# в ходе перекрестной проверки на holdout data\n",
    "print('F1 HOLDOUT: %.3f' % f1_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=metrics.append(get_metrics(y_test=y_test,\n",
    "                y_pred=test_pred,\n",
    "                y_score=test_pred_proba,\n",
    "                name='CatBoost_Optuna_Holdout_test'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "train_pred_proba = model.predict_proba(X_train)\n",
    "\n",
    "metrics=metrics.append(get_metrics(y_test=y_train,\n",
    "                y_pred=train_pred,\n",
    "                y_score=train_pred_proba,\n",
    "                name='CatBoost_Optuna_Holdout_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d88980",
   "metadata": {},
   "source": [
    "## 4. RandomForest holdout+optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=RAND, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin = pd.get_dummies(X, drop_first=True)\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=RAND)\n",
    "\n",
    "\n",
    "\n",
    "def objective_rf(trial, X, y, N_FOLDS, rand):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", ['gini', 'entropy', 'log_loss']),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        'bootstrap': trial.suggest_categorical(\"bootstrap\", [True]),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'max_samples': trial.suggest_float('max_samples', 0.3, 0.99),\n",
    "        'max_features': trial.suggest_categorical(\"max_features\", ['auto', 'sqrt', 'log2']),\n",
    "        'class_weight': trial.suggest_categorical(\"class_weight\", ['balanced']),\n",
    "        #'random_state': [rand] \n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=rand)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        model = RandomForestClassifier(**params, n_jobs=-1, random_state=rand)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = f1_score(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430cc0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study_rf = optuna.create_study(direction=\"maximize\", study_name=\"RF_01\")\n",
    "func = lambda trial: objective_rf(trial, X_train_bin, y_train, N_FOLDS, rand=RAND)\n",
    "# n_trials - кол-во итераций\n",
    "study_rf.optimize(func, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "А тут уже функцию ранее не используете =) как то не логично\n",
    "давайте убирать ту функцию выше, делайте для катбуста как тут\n",
    "\"\"\"\n",
    "\n",
    "pred_val = []\n",
    "pred_score_val = []\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(cv.split(X_train_bin, y_train)):\n",
    "    X_train_, X_val = X_train_bin.iloc[train_index], X_train_bin.iloc[test_index]\n",
    "    y_train_, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(**study_rf.best_params, n_jobs=-1)\n",
    "    model.fit(X_train_, y_train_)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "\n",
    "    print(\"Fold:\", fold + 1,\n",
    "          \"F1 SCORE %.3f\" % f1_score(y_val, y_pred_val))\n",
    "    print(\"---\")\n",
    "\n",
    "    # holdout list\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)\n",
    "\n",
    "model.fit(X_train_bin, y_train)\n",
    "\n",
    "meta_X['rf_01'] = np.concatenate(pred_score_val)[:,1]\n",
    "meta_X_test['rf_01'] = model.predict_proba(X_test_bin)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab303a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40053b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "y_score = rf.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test, y_pred, y_score, \n",
    "                                     name='RandomForestClassifier_test'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6014b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = rf.predict_proba(X_train)\n",
    "y_pred_cat_train = rf.predict(X_train)\n",
    "\n",
    "metrics =metrics.append(get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='RandomForestClassifier_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0ce6a",
   "metadata": {},
   "source": [
    "## 5. LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401c5ea",
   "metadata": {},
   "source": [
    "### 5.1. LGBM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ea302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clfLGBM = LGBMClassifier(scale_pos_weight=3, random_state=RAND)\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clfLGBM.fit(X_train_,\n",
    "        y_train_,\n",
    "        eval_metric=\"F1\",\n",
    "        eval_set=eval_set,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=2)\n",
    "\n",
    "y_pred = clfLGBM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024aa7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clfLGBM.predict(X_test)\n",
    "y_score = clfLGBM.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test=y_test,\n",
    "                y_pred=y_pred,\n",
    "                y_score=y_score,\n",
    "                name='LGBMboost_eval_baseline_test'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = clfLGBM.predict_proba(X_train)\n",
    "y_pred_cat_train = clfLGBM.predict(X_train)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='LGBMboost_eval_baseline_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca08f29",
   "metadata": {},
   "source": [
    "### 5.2. LGBM Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb_first(trial, X, y, N_FOLDS, random_state=10):\n",
    "    lgb_params = {\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_float(\"learning_rate\", 0.001, 0.3, log=True)\n",
    "    }\n",
    "\n",
    "    N_FOLDS = 3\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # стрижка \"на лету\"\n",
    "        # observation_key - Оценочная метрика для обрезки\n",
    "        model = LGBMClassifier(**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric=\"F1\",\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = f1_score(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e310beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGB_21\")\n",
    "\n",
    "\n",
    "def func(trial): return objective_lgb_first(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "\n",
    "\n",
    "# n_trials - кол-во итераций\n",
    "study.optimize(func, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ba9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb_second(trial, X, y, N_FOLDS, random_state=10):\n",
    "    lgb_params = {\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.013607708322422411]),\n",
    "        \"num_leaves\":\n",
    "        trial.suggest_int(\"num_leaves\", 20, 1000, step=20),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"lambda_l1\":\n",
    "        trial.suggest_int(\"lambda_l1\", 0, 100),\n",
    "        \"lambda_l2\":\n",
    "        trial.suggest_int(\"lambda_l2\", 0, 100),\n",
    "        \"min_gain_to_split\":\n",
    "        trial.suggest_int(\"min_gain_to_split\", 0, 20),\n",
    "        \"bagging_fraction\":\n",
    "        trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        \"bagging_freq\":\n",
    "        trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\":\n",
    "        trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "        # \"objective\": trial.suggest_categorical(\"objective\", [\"mae\"]),\n",
    "        \"random_state\":\n",
    "        RAND\n",
    "    }\n",
    "\n",
    "    N_FOLDS = 3\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # стрижка \"на лету\"\n",
    "        # observation_key - Оценочная метрика для обрезки\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(\n",
    "            trial, \"F1\")\n",
    "        model = LGBMClassifier(**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric=\"F1\",\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = f1_score(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGB_22\")\n",
    "func = lambda trial: objective_lgb_second(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "# n_trials - кол-во итераций\n",
    "study.optimize(func, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20e21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgb_grid = LGBMClassifier(**study.best_params)\n",
    "lgb_grid.fit(X_train_,\n",
    "             y_train_,\n",
    "             eval_metric=\"F1\",\n",
    "             eval_set=eval_set,\n",
    "             verbose=False,\n",
    "             early_stopping_rounds=100)\n",
    "\n",
    "y_pred = lgb_grid.predict(X_test)\n",
    "y_score = lgb_grid.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test=y_test.values,\n",
    "                y_pred=y_pred,\n",
    "                y_score=y_score,\n",
    "                name='LGBoost_Optuna_test'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = lgb_grid.predict_proba(X_train)\n",
    "y_pred_cat_train = lgb_grid.predict(X_train)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='LGBoost_Optuna_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d948b",
   "metadata": {},
   "source": [
    "### 5.3. LGBM Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = []\n",
    "pred_score_val = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_, y_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    model = LGBMClassifier(is_unbalance=True, random_state=RAND)\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric=\"F1\",\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "\n",
    "    print(\"Fold:\", fold + 1,\n",
    "          \"F1 SCORE %.3f\" % f1_score(y_val, y_pred_val))\n",
    "    print(\"---\")\n",
    "\n",
    "    # holdout list\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "meta_X['lgb_01'] = np.concatenate(pred_score_val)[:, 1]\n",
    "meta_X_test['lgb_01'] = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_oof = []\n",
    "predictions_test = []\n",
    "finish_test_preds_proba = []\n",
    "pred_val = []\n",
    "pred_score_val = []\n",
    "early_stop=True\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_val = X_train.iloc[train_idx], X_train.iloc[train_idx]\n",
    "    y_train_, y_val = y_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    \n",
    "    model = LGBMClassifier(**study.best_params)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "                y_train_,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                eval_metric=\"F1\",\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=0)\n",
    "\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds_test_proba = model.predict_proba(X_test)\n",
    "    finish_test_preds_proba.append(preds_test_proba)\n",
    "\n",
    "    print(\n",
    "        \"Fold:\", fold + 1,\n",
    "        \"f1_score %.3f\" % f1_score(y_val, y_pred_val))\n",
    "    print(\"---\")\n",
    "\n",
    "    # oof list\n",
    "    score_oof.append(f1_score(y_val, y_pred_val))\n",
    "    # holdout list\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "    predictions_test.append(y_pred)\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)\n",
    "    \n",
    "meta_X['lgb_02'] = model.predict_proba(X_train)[:, 1]\n",
    "meta_X_test['lgb_02'] = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4116e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = np.mean(finish_test_preds_proba, axis=0)\n",
    "test_pred = stats.mode(np.column_stack(predictions_test), axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42312bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.append(\n",
    "    get_metrics(y_test=y_test,\n",
    "                y_pred=test_pred,\n",
    "                y_score=test_pred_proba,\n",
    "                name='LGBM_Holdout_test'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a239b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = model.predict_proba(X_train)\n",
    "y_pred_cat_train = model.predict(X_train)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='LGBM_Holdout_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdca2d",
   "metadata": {},
   "source": [
    "## 6. xgboost holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "score_oof = []\n",
    "predictions_test = []\n",
    "finish_test_preds_proba = []\n",
    "pred_val = []\n",
    "pred_score_val = []\n",
    "early_stop=True\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_train_bin, y_train)):\n",
    "    X_train_, X_val = X_train_bin.iloc[train_idx], X_train_bin.iloc[test_idx]\n",
    "    y_train_, y_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    \n",
    "    model = XGBClassifier(scale_pos_weight=3, random_state=RAND)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "                y_train_,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                eval_metric=\"logloss\",\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=0)\n",
    "\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds_test_proba = model.predict_proba(X_test)\n",
    "    finish_test_preds_proba.append(preds_test_proba)\n",
    "\n",
    "    print(\n",
    "        \"Fold:\", fold + 1,\n",
    "        \"f1_score %.3f\" % f1_score(y_val, y_pred_val))\n",
    "    print(\"---\")\n",
    "\n",
    "    # oof list\n",
    "    score_oof.append(f1_score(y_val, y_pred_val))\n",
    "    # holdout list\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "    predictions_test.append(y_pred)\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)\n",
    "    \n",
    "meta_X['xgb_01'] = model.predict_proba(X_train)[:, 1]\n",
    "meta_X_test['xgb_01'] = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = np.mean(finish_test_preds_proba, axis=0)\n",
    "test_pred = stats.mode(np.column_stack(predictions_test), axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=metrics.append(get_metrics(y_test=y_test,\n",
    "                y_pred=test_pred,\n",
    "                y_score=test_pred_proba,\n",
    "                name='XGB_Holdout_test'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_train = model.predict_proba(X_train)\n",
    "y_pred_cat_train = model.predict(X_train)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train,\n",
    "                y_pred_cat_train,\n",
    "                y_score_train,\n",
    "                name='XGB_Holdout_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf7b01",
   "metadata": {},
   "source": [
    "## 7. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4894fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f254c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_train = pd.DataFrame(data=y_train)\n",
    "df_label_train = df_label_train.reset_index()\n",
    "meta_X_final=pd.concat([meta_X, df_label_train], axis=1)\n",
    "meta_X_final.drop(['index'], axis=1, inplace=True)\n",
    "meta_X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a580b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_final = meta_X_final['Label']\n",
    "X_train_final = meta_X_final.drop(['Label'], axis=1)\n",
    "\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_train_final,\n",
    "                                                            y_train_final,\n",
    "                                                            test_size=0.2,\n",
    "                                                            stratify=y_train,\n",
    "                                                            random_state=RAND)\n",
    "\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train_f,\n",
    "                                                    y_train_f,\n",
    "                                                    test_size=0.16,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=RAND)\n",
    "\n",
    "clfcat = CatBoostClassifier(scale_pos_weight=3,\n",
    "                            random_state=RAND,\n",
    "                            eval_metric=\"F1\")\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clfcat.fit(X_train_,\n",
    "           y_train_,\n",
    "           eval_set=eval_set,\n",
    "           early_stopping_rounds=100,\n",
    "           verbose=False)\n",
    "\n",
    "y_pred = clfcat.predict(meta_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clfcat.predict_proba(meta_X_test)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test=y_test, y_pred=y_pred, y_score=y_score,\n",
    "                name='Stacking_test'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e625a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clfcat.predict_proba(meta_X)\n",
    "y_pred = clfcat.predict(meta_X)\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test=y_train, y_pred=y_pred, y_score=y_score,\n",
    "                name='Stacking_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b64aaa5",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- 1) Лучшие показатели f1, roc_auc, logloss на тестовых данных выдал CatBoost_Optuna_Holdout \n",
    "- 2) Самые непереобученные модели: LGBoost_Optuna, LGBM_Holdout.\n",
    "- 3) Stacking не показал хороших результатов на тестовых данных, но показал лучшие результаты, среди моих моделей, на скрытых данных, по которым и ставится оценка в соревновании\n",
    "- 4) RandomForest показал одни и самых плохих результатов по основным метрикам, но лучший по Precision. Поэтому я оставил его в стэкинге.\n",
    "- 5) Пробовал разное кол-во и состав моделей для стекинга. Самые лучшие метрики на скрытых данных получились у этих 5 моделей.\n",
    "- 6) Метрики на тестовых данных и на скрытых данных не коррелировали между собой, поэтому обучение для соревнований проходило вслепую."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf5d41",
   "metadata": {},
   "source": [
    "[11 место в соревновании](https://zindi.africa/competitions/landslide-prevention-and-innovation-challenge/leaderboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
